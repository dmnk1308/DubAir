{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "import requests\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import urllib.request as urli\n",
    "import os \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_listing = \"http://data.insideairbnb.com/germany/bv/munich/2021-12-24/data/listings.csv.gz\"\n",
    "listings = pd.read_csv(url_listing)\n",
    "prefix = \"https://airbnb.de\"\n",
    "suffix = \"/photos\"\n",
    "urls = listings[\"listing_url\"]\n",
    "ids = listings[\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4995 [00:00<?, ?it/s]C:\\Users\\49173\\anaconda3\\envs\\DL_tabnet\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \n",
      "C:\\Users\\49173\\anaconda3\\envs\\DL_tabnet\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  if __name__ == '__main__':\n",
      " 56%|█████▋    | 2822/4995 [10:09:51<6:23:42, 10.59s/it] "
     ]
    }
   ],
   "source": [
    "id_dict = dict()\n",
    "for id, url in tqdm(zip(ids, urls), total = len(ids)):    \n",
    "    id_list = []\n",
    "    try:\n",
    "        #driver = webdriver.Chrome(\"/Users/dmnk/Documents/Dubair_Trash/chromedriver 2\", options = options)\n",
    "        driver = webdriver.Chrome(\"D:/Sonstiges/chromedriver.exe\", options = options)\n",
    "        driver.get(url+suffix)\n",
    "\n",
    "        body = driver.find_element_by_tag_name(\"body\")\n",
    "        for i in range(40):\n",
    "            body.send_keys(Keys.TAB)\n",
    "        \n",
    "        time.sleep(1)\n",
    "\n",
    "        for i in range(40):\n",
    "            body.send_keys(Keys.TAB)            \n",
    "\n",
    "        html = driver.page_source\n",
    "        html_content = BeautifulSoup(html, \"html.parser\")\n",
    "        gallery_items = html_content.findAll(\"img\", {\"class\": \"_6tbg2q\"})\n",
    "    except:\n",
    "        continue\n",
    "    for i, item in enumerate(gallery_items[5:]):\n",
    "        try:\n",
    "            img_link = item.get(\"src\")\n",
    "            img_title = item.get(\"alt\")\n",
    "            path_name = \"D:/Uni/WiSe21-22/Statistical and Deep Learning/image_scraping_munich/\"+str(id)+\"_\"+str(i)+\".png\"\n",
    "            if os.path.exists(path_name):\n",
    "                id_list.append(img_title)\n",
    "                continue\n",
    "            else:\n",
    "                urli.urlretrieve(img_link, path_name)\n",
    "                id_list.append(img_title)\n",
    "            \n",
    "        except:\n",
    "            print(\"ups - fail\")\n",
    "            continue\n",
    "\n",
    "    id_dict[id] = id_list\n",
    "meta_images = open(\"D:/Uni/WiSe21-22/Statistical and Deep Learning/image_scraping_munich/data.pkl\", \"wb\")\n",
    "pickle.dump(id_dict, meta_images)\n",
    "meta_images.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('labels_raw.json', 'w') as fp:\n",
    "    json.dump(id_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize images to same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 86889/86890 [34:07<00:00, 42.43it/s]  \n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5648\\3729764274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mimg_dir_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"D:/Uni/WiSe21-22/Statistical and Deep Learning/image_scraping/\"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mimg_dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[0mimg_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dir_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[0mimg_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m   \u001b[0mpath_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresized_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mresized_img_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_tmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_tmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "resized_path = \"D:/Uni/WiSe21-22/Statistical and Deep Learning/images_resized/\"\n",
    "\n",
    "dir = os.listdir(\"D:/Uni/WiSe21-22/Statistical and Deep Learning/image_scraping\")\n",
    "\n",
    "img_names = pd.Series(dir).str.split(\".\").str[0].values\n",
    "\n",
    "for img_dir, resized_img_dir in tqdm(zip(dir, img_names), total = len(dir)):\n",
    "  img_dir_tmp = \"D:/Uni/WiSe21-22/Statistical and Deep Learning/image_scraping/\"+ img_dir\n",
    "  img_tmp = cv2.imread(img_dir_tmp)\n",
    "  img_tmp = cv2.resize(img_tmp, dsize=(256, 256))\n",
    "  path_tmp = resized_path + resized_img_dir + \".png\"\n",
    "  cv2.imwrite(path_tmp, img_tmp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4bd624a0593993fe43ac4046b27b898fb2ef75c21c08f81e89e64ea0f51df676"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

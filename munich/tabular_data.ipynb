{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/dmnk/OneDrive - stud.uni-goettingen.de/Dokumente/3. Semester/SeminarDL/DubAir\")\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import ast\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import halfnorm\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Wrangler:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.relevant_variables = [\"id\", \"name\", \"last_scraped\", \"description\", \"neighborhood_overview\", \"host_id\", \"host_url\", \"host_name\", \"host_since\", \"host_location\",\n",
    "                                \"host_about\", \"host_is_superhost\", \"host_listings_count\", \"host_has_profile_picture\",\"host_identity_verified\",\n",
    "                                \"neighbourhood_cleansed\",\n",
    "                                \"latitude\",\n",
    "                                \"longitude\",\n",
    "                                \"property_type\",\n",
    "                                \"room_type\",\n",
    "                                \"accommodates\",\n",
    "                                \"bathrooms_text\",\n",
    "                                \"bedrooms\",\n",
    "                                \"beds\",\n",
    "                                \"amenities\",\n",
    "                                \"minimum_nights\",\n",
    "                                \"maximum_nights\",\n",
    "                                \"has_availability\",\n",
    "                                \"availability_30\",\n",
    "                                \"availability_60\",\n",
    "                                \"availability_90\",\n",
    "                                \"availability_365\",\n",
    "                                \"number_of_reviews\",\n",
    "                                \"number_of_reviews_ltm\", \n",
    "                                \"number_of_reviews_l30d\", \n",
    "                                \"first_review\",\n",
    "                                \"last_review\",\n",
    "                                \"review_scores_rating\",\t \n",
    "                                \"review_scores_accuracy\",\t\n",
    "                                \"review_scores_cleanliness\",\n",
    "                                \"review_scores_checkin\t\",\n",
    "                                \"review_scores_communication\",\n",
    "                                \"review_scores_location\",\t\n",
    "                                \"review_scores_value\",\n",
    "                                \"instant_bookable\",\n",
    "                                \"calculated_host_listings_count\",\n",
    "                                \"reviews_per_month\",\n",
    "                                \"host_has_profile_pic\",\n",
    "                                'minimum_minimum_nights', \n",
    "                                'maximum_minimum_nights', \n",
    "                                'minimum_maximum_nights', \n",
    "                                'maximum_maximum_nights', \n",
    "                                'minimum_nights_avg_ntm', \n",
    "                                'maximum_nights_avg_ntm',\n",
    "                                'calculated_host_listings_count_entire_homes', \n",
    "                                'calculated_host_listings_count_private_rooms', \n",
    "                                'calculated_host_listings_count_shared_rooms', \"price\"] \n",
    "        \n",
    "    def preprocess(self):\n",
    "        self.data = self.data.reset_index(drop = True)\n",
    "\n",
    "        # get rid of Hotels\n",
    "        hotel_filter = self.data[\"room_type\"] == \"Hotel room\"\n",
    "        self.data = self.data[~hotel_filter]\n",
    "        # clean hotel, hostels again\n",
    "        prop = self.data[\"property_type\"]\n",
    "        filter_prop = prop.str.contains(\"hotel\", case = False)\n",
    "        self.data = self.data[~filter_prop]\n",
    "        prop = self.data[\"property_type\"]\n",
    "        filter_prop = prop.str.contains(\"hostel\", case = False)\n",
    "        self.data = self.data[~filter_prop]\n",
    "         # remove everything unimportant\n",
    "        self.data = self.data.filter(self.relevant_variables)\n",
    "        \n",
    "        \n",
    "        #### Preprocess ####\n",
    "        \n",
    "        # clean host_profile_pic\n",
    "        self.data[\"host_has_profile_pic\"] = np.where(self.data[\"host_has_profile_pic\"] == \"t\", 1, 0)\n",
    "        self.data[\"host_is_superhost\"] = np.where(self.data[\"host_is_superhost\"] == \"t\", 1, 0)\n",
    "        self.data[\"host_identity_verified\"] = np.where(self.data[\"host_identity_verified\"] == \"t\", 1, 0)\n",
    "        self.data[\"has_availability\"] = np.where(self.data[\"has_availability\"] == \"t\", 1, 0)\n",
    "        self.data[\"instant_bookable\"] = np.where(self.data[\"instant_bookable\"] == \"t\", 1, 0)\n",
    "\n",
    "\n",
    "        # clean bathroom text\n",
    "        na_filter = self.data[\"bathrooms_text\"].isna()\n",
    "        self.data = self.data[~na_filter]\n",
    "        bath_number = self.data[\"bathrooms_text\"].copy()\n",
    "        bath_number = bath_number.str.replace(\"half\", \"0.5\", case = False)\n",
    "        bath_number = bath_number.str.extract('(\\d+.\\d|\\d+)')\n",
    "        self.data[\"bath_number\"] = bath_number.astype(float)\n",
    "        bath_kind = self.data[\"bathrooms_text\"].copy()\n",
    "        shared = bath_kind.str.contains(\"shared\", case = False)\n",
    "        private = bath_kind.str.contains(\"private\", case = False)\n",
    "        normal = ~pd.concat([shared, private], axis = 1).any(axis = 1)\n",
    "        bath_kind[shared] = \"Shared\"\n",
    "        bath_kind[private] = \"Private\"\n",
    "        bath_kind[normal] = \"Normal\"\n",
    "        self.data[\"bath_kind\"] = bath_kind\n",
    "        self.data = self.data.drop(\"bathrooms_text\", axis = 1)\n",
    "\n",
    "        # clean property types\n",
    "        ## sum up all properties that occur less than 10 times in \"others\"\n",
    "        values = self.data[\"property_type\"].value_counts()\n",
    "        other_list = values.where(values<=10).dropna().index\n",
    "        for i, j in enumerate(other_list):\n",
    "            fil = self.data[\"property_type\"].str.contains(j, case = True, na = False)\n",
    "            self.data.loc[fil,\"property_type\"] = \"Others\"\n",
    "\n",
    "        return self.data\n",
    "    \n",
    "    def process_amenities(self, fit = True):\n",
    "        self.data = self.data.reset_index(drop = True)\n",
    "        # AMENITIES\n",
    "        # load amenities\n",
    "        amenities = self.data[\"amenities\"]\n",
    "        amenities = amenities.apply(ast.literal_eval)\n",
    "\n",
    "        # we hava a list as each cell of the amenities pd.Series. Unpack them\n",
    "        if fit:\n",
    "            mlb_amenities = MultiLabelBinarizer()\n",
    "            mlb_amenities.fit(amenities)\n",
    "            self.mlb_amenities = mlb_amenities\n",
    "        \n",
    "        am_array = self.mlb_amenities.transform(amenities)\n",
    "        am_df = pd.DataFrame(am_array, columns = self.mlb_amenities.classes_)\n",
    "        # drop some stuff that is too broad, too standard or to specific\n",
    "        am_df = drop_col(am_df, \"(Clothing storage)\")\n",
    "        am_df = drop_col(am_df, \"(^Fast wifi.)\")    \n",
    "\n",
    "        # am_df = drop_col(am_df, [\"Bedroom comforts\", \"Bread maker\",\"Carbon monoxide alarm\",\n",
    "        # \"Children’s dinnerware\", \"Drying rack for clothing\", \"Fireplace guards\", \"Fire extinguisher\", \n",
    "        # \"Hot water kettle\", \"Hangers\", \"Iron\", \"Keypad\", \"Pocket wifi\", \"Mini fridge\",\n",
    "        # \"Mosquito net\", \"Outlet covers\", \"Pour-over coffee\", \"Portable fans\",\n",
    "        # \"Portable heater\", \"Portable air conditioning\", \"Radiant heating\", \"Record player\", \n",
    "        # \"Rice maker\", \"Shower gel\", \"Ski-in/Ski-out\", \"Table corner guards\", \"Trash compactor\",\n",
    "        # \"Wine glasses\", \"Window guards\", \"Baking sheet\", \"Barbecue utensils\", \"Boat slip\",\n",
    "        # \"Cable TV\",\"Changing table\",\"Cleaning products\",\"EV charger\",\"Ethernet connection\", \n",
    "        # \"Extra pillows and blankets\", \"First aid kit\",\"Laundromat nearby\", \"Room-darkening shades\",\n",
    "        # \"Smart lock\", \"Smoke alarm\", \"Toaster\", \"Microwave\", \"Essentials\", \"Bathroom essentials\", \"Fire pit\", \n",
    "        # \"Lock on bedroom door\", \"Hot water\", \"Beach essentials\", \"Board games\", \"Building staff\", \n",
    "        # \"Cooking basics\", \"Dining table\", \"Dishes and silverware\", \"Host greets you\", \"Luggage dropoff allowed\", \n",
    "        # \"Self check-in\", \"Pets allowed\", \"Suitable for events\", \"Ceiling fan\"], regex = False)\n",
    "\n",
    "        # summarize in new columns which gives the availability\n",
    "        am_df = in_one(am_df, \"(.oven)|(^oven)\", \"Oven_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(.stove)|(^stove)\", \"Stoves_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(refrigerator.)|(refrigerator)|(^Freezer$)\", \"Refridgerator_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(body soap)\", \"Body_soap_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(garden or backyard)|(^backyard)|(^garden)\", \"Garden_backyard_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^free.*parking)|(^free.*garage)|(^free.*carport)\", \"Free_parking\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^paid.*parking)|(^paid.*garage)|(^paid.*carport)\", \"Paid_parking\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Children’s books and toys)\", \"Children_Entertainment\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Dedicated workspace)\", \"Workspace\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(conditioner)|(shampoo)\", \"Shampoo_Conditioner_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Gym)|(. gym)\", \"Gym_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(coffee machine)|(Nespresso)|(^Coffee maker)\", \"Coffee_machine_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Dryer)|(Paid dryer)|(^Free dryer)\", \"Dryer_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Washer)|(Paid washer)|(Free washer)\", \"Washer_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Hot tub)|(.hot tub)\", \"Hot_tub_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Pool)|(shared.*pool)|(private.*pool)\", \"Pool_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(patio or balcony)\", \"Patio_balcony_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Wifi)\", \"Wifi_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(air conditioning)\", \"AC_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(heating)\", \"heating_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Kitchen$)|(^Full kitchen$)\", \"Kitchen_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Lockbox$)|(^Safe$)\", \"Safe_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(sauna)\", \"Sauna_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Waterfront$)|(^Beachfront$)|(^Lake access$)\", \"Water_location\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(sound system)\", \"sound_system_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(HDTV)|(^\\d\\d..TV)|(^TV)\", \"TV_available\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^outdoor)\", \"Outdoor_stuff\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(game console)\", \"Game_consoles\", regex = True, sum = False, drop = True)\n",
    "        am_df = in_one(am_df, \"(^Baby)|(^Crib$)|( crib$)|(^High chair$)\", \"Baby_friendly\", regex = True, sum = False, drop = True)\n",
    "\n",
    "        # sum up all luxury or extraordinary equipment\n",
    "        am_df = in_one(am_df, [\"Piano\", \"Ping pong table\", \"Kayak\", \"BBQ grill\", \"Bidet\", \"Bikes\", \"Sauna_available\"], \"Special_stuff\", regex = False, sum = False, drop = True)\n",
    "\n",
    "\n",
    "        if fit:\n",
    "            sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "            sel.feature_names_in_ = am_df.columns\n",
    "            self.variance_threshold_am = sel.fit(am_df)\n",
    "        \n",
    "        am_col = self.variance_threshold_am.get_feature_names_out()\n",
    "        print(str(len(am_df.columns) - len(am_col)) + \" amenities have been removed due to close zero-variance.\")\n",
    "        am_df = am_df.filter(am_col)\n",
    "        # join amenities with listings\n",
    "\n",
    "        self.data = pd.concat([self.data, am_df], axis = 1)\n",
    "        # drop amenities columns\n",
    "        self.data = self.data.drop(\"amenities\", axis = 1)\n",
    "        \n",
    "        return self.data\n",
    "        \n",
    "    def add_stuff(self, munich = False):\n",
    "        \n",
    "        # ADD TEXT STUFF\n",
    "        # lengths of text columns\n",
    "        self.data[\"name_length\"] = self.data[\"name\"].astype(str).str.replace(\" \",\"\").str.len()\n",
    "        self.data[\"description_length\"] = self.data[\"description\"].astype(str).str.replace(\" \",\"\").str.len()\n",
    "        self.data[\"neighborhood_overview_length\"] = self.data[\"neighborhood_overview\"].astype(str).str.replace(\" \",\"\").str.len()\n",
    "        self.data[\"host_about_length\"] = self.data[\"host_about\"].astype(str).str.replace(\" \",\"\").str.len()\n",
    "       \n",
    "        if munich == True:\n",
    "            # read in pre-created frames\n",
    "            listings_reviews = pd.read_csv(\"munich/listings_reviews_munich.csv\")\n",
    "            host_sent = pd.read_csv(\"munich/host_sent_munich.csv\")\n",
    "            host_name = pd.read_csv(\"munich/host_name_munich.csv\")\n",
    "            host_sent = host_sent.drop(host_sent.columns[0], axis=1)\n",
    "            host_name = host_name.drop(host_name.columns[0], axis=1)        \n",
    "            listings_reviews = listings_reviews.drop(listings_reviews.columns[0], axis=1)\n",
    "\n",
    "            # add to listings\n",
    "            self.data = pd.merge(self.data, listings_reviews, on=\"id\", how=\"left\")\n",
    "            host_sent = pd.concat([host_sent, host_name], axis=1)\n",
    "            self.data = pd.merge(self.data, host_sent, on=\"id\", how=\"left\")\n",
    "\n",
    "            # ADD OSM STUFF\n",
    "            listings_osm = pd.read_csv(\"munich/StreetData_munich.csv\")\n",
    "            listings_osm = listings_osm.drop(listings_osm.columns[0], axis=1)\n",
    "            self.data = pd.merge(self.data, listings_osm, on=\"id\", how=\"left\")\n",
    "    \n",
    "        if munich == False:\n",
    "            # read in pre-created frames\n",
    "            listings_reviews = pd.read_csv(\"text_data/listings_reviews.csv\")\n",
    "            host_sent = pd.read_csv(\"text_data/host_sent.csv\")\n",
    "            host_name = pd.read_csv(\"text_data/host_name.csv\")\n",
    "            host_sent = host_sent.drop(host_sent.columns[0], axis=1)\n",
    "            host_name = host_name.drop(host_name.columns[0], axis=1)        \n",
    "            listings_reviews = listings_reviews.drop(listings_reviews.columns[0], axis=1)\n",
    "\n",
    "            # add to listings\n",
    "            self.data = pd.merge(self.data, listings_reviews, on=\"id\", how=\"left\")\n",
    "            host_sent = pd.concat([host_sent, host_name], axis=1)\n",
    "            self.data = pd.merge(self.data, host_sent, on=\"id\", how=\"left\")\n",
    "\n",
    "            # ADD OSM STUFF\n",
    "            listings_osm = pd.read_csv(\"StreetData.csv\")\n",
    "            listings_osm = listings_osm.drop(listings_osm.columns[0], axis=1)\n",
    "            self.data = pd.merge(self.data, listings_osm, on=\"id\", how=\"left\")\n",
    "            \n",
    "        # ADD IMAGE STUFF\n",
    "        img_df = pd.read_csv(\"data/img_info.csv\")\n",
    "        self.data = self.data.merge(img_df, how = \"left\", on = \"id\")\n",
    "        self.data.drop(\"index\", axis =1, inplace = True)\n",
    "        print(\"Text, OpenStreet and image data loaded.\")\n",
    "        return self.data\n",
    "\n",
    "    def fit_first(self):\n",
    "        # IMPUTATION STUFF\n",
    "        # FIT MODEL FOR BEDS\n",
    "        # accomodates and beds are quite linear\n",
    "        # So let us estimate linear models and predict, for beds\n",
    "        Y = self.data[\"beds\"]\n",
    "        x = self.data[\"accommodates\"]\n",
    "        X = pd.DataFrame([x]).transpose()\n",
    "        X = sm.add_constant(X)  # adding a constant\n",
    "        self.model_OLS_beds = sm.OLS(Y, X, missing='drop').fit()\n",
    "\n",
    "        # FIT MODEL FOR BEDROOMS\n",
    "        # beds and bedrooms are very linear as well\n",
    "        # do the same here\n",
    "        Y = self.data[\"bedrooms\"]\n",
    "        x = self.data[\"beds\"]\n",
    "        X = pd.DataFrame([x]).transpose()\n",
    "        X = sm.add_constant(X)  # adding a constant\n",
    "        self.model_OLS_bedrooms = sm.OLS(Y, X, missing='drop').fit()\n",
    "\n",
    "        # SAVE SD FOR EACH REVIEW VARIABLE\n",
    "        # All those review score variables\n",
    "        self.review_var = ['review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n",
    "                    'review_scores_communication', 'review_scores_location', 'review_scores_value']\n",
    "        # they look quite halfnormal\n",
    "        sds = []\n",
    "        for i in range(len(self.review_var)):\n",
    "            sd = np.nanstd(self.data[self.review_var[i]],  ddof=0)  # ML-estimator\n",
    "            sds.append(sd - sd / (4 * len(self.data[self.review_var[i]])))  # MLE bias corrected          \n",
    "        self.sd_reviews = sds    \n",
    "        \n",
    "        # HOST LOCATION\n",
    "        # clean host_location\n",
    "        country_abr = pd.read_csv(\"https://gist.githubusercontent.com/radcliff/f09c0f88344a7fcef373/raw/2753c482ad091c54b1822288ad2e4811c021d8ec/wikipedia-iso-country-codes.csv\")\n",
    "        country_list = list(country_abr.iloc[:,0])\n",
    "        abr_list = list(country_abr.iloc[:,1])\n",
    "\n",
    "        self.data[\"host_location_country\"] = self.data[\"host_location\"].copy()\n",
    "\n",
    "        for i in list(country_list):\n",
    "            fil = self.data[\"host_location\"].str.contains(i, case = False, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = str(i)\n",
    "\n",
    "        for i,j in enumerate(list(abr_list)):\n",
    "            fil = self.data[\"host_location\"].str.contains(str(j), case = True, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = str(country_list[i])\n",
    "\n",
    "        other_filter = self.data[\"host_location_country\"].value_counts() <= 5\n",
    "        self.country_list = list(self.data[\"host_location_country\"].value_counts().index[other_filter])\n",
    "\n",
    "        for i, j in enumerate(self.country_list):\n",
    "            fil = self.data[\"host_location_country\"].str.contains(j, case = True, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = \"Others\"\n",
    "        self.data.loc[self.data[\"host_location_country\"] == \"53.357852, -6.259787\", \"host_location_country\"] = \"Ireland\"\n",
    "        \n",
    "        # PIs FOR BINARY VARIABLES\n",
    "        ### Binary Stuff\n",
    "        # self.rest_var = ['Bathtub', 'Bed linens', 'Breakfast', 'Cleaning before checkout', 'Dishwasher',\n",
    "        #             'Elevator', 'Hair dryer', 'Indoor fireplace', 'Long term stays allowed',\n",
    "        #             'Private entrance', 'Security cameras on property', 'Single level home',\n",
    "        #             'Special_stuff', 'TV_available', 'Outdoor_stuff', 'Baby_friendly',\n",
    "        #             'sound_system_available', 'Oven_available', 'Stoves_available',\n",
    "        #             'Refridgerator_available', 'Body_soap_available',\n",
    "        #             'Garden_backyard_available', 'Free_parking',\n",
    "        #             'Paid_parking', 'Children_Entertainment', 'Workspace',\n",
    "        #             'Shampoo_Conditioner_available', 'Gym_available',\n",
    "        #             'Coffee_machine_available', 'Dryer_available', 'Washer_available',\n",
    "        #             'Hot_tub_available', 'Pool_available', 'Patio_balcony_available',\n",
    "        #             'Wifi_available', 'AC_available', 'heating_available',\n",
    "        #             'Kitchen_available', 'Safe_available', 'Water_location', \"Game_consoles\"]\n",
    "        \n",
    "        self.rest_var = [col for col in self.data if np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "\n",
    "        pis = []\n",
    "        for i in range(len(self.rest_var)):\n",
    "            pis.append(np.nanmean(self.data[self.rest_var[i]]))\n",
    "        self.pis = pis\n",
    "        \n",
    "        # MEANS FOR TEXT STUFF\n",
    "        self.text_var = [\"prop_of_eng_reviews\", \"mean_compound\", \"mean_negativity\", \"mean_neutrality\",\"mean_positivity\",\"mean_review_length\",\n",
    "                         \"prop_of_neg_comp\", \"most_neg_compound\",\"most_pos_compound\"]\n",
    "        means_text = []\n",
    "        for i in self.text_var:\n",
    "            means_text.append(self.data[i].mean())\n",
    "        self.means_text = means_text\n",
    "            \n",
    "        # MEANS FOR IMAGE STUFF\n",
    "        img_df = pd.read_csv(\"data/img_info.csv\")\n",
    "        means = img_df.mean(axis = 0)\n",
    "        self.mean_brightness = means[2]\n",
    "        self.mean_contrast = means[3]  \n",
    "        \n",
    "        \n",
    "        ### APPLY HERE FOR FOLLOWING FITS\n",
    "        # OLS BEDS\n",
    "        ind = self.data[self.data[\"beds\"].isna()][\"beds\"].index\n",
    "        x0 = self.data[\"accommodates\"][ind]\n",
    "        x0 = sm.add_constant(x0)\n",
    "        predictions = self.model_OLS_beds.predict(x0)\n",
    "        prediction = np.where(predictions <= 0.5, 1, predictions)   \n",
    "        self.data.loc[ind, \"beds\"] = round(predictions)\n",
    "        \n",
    "        # OLS BEDROOMS\n",
    "        ind = self.data[self.data[\"bedrooms\"].isna()][\"bedrooms\"].index\n",
    "        x0 = self.data[\"beds\"][ind]\n",
    "        x0 = sm.add_constant(x0)\n",
    "        predictions = self.model_OLS_bedrooms.predict(x0)\n",
    "        prediction = np.where(predictions <= 0.5, 1, predictions)   \n",
    "        self.data.loc[ind, \"bedrooms\"] = round(predictions)          \n",
    "        \n",
    "        # ONE HOT\n",
    "        listings_fit = self.data.copy()\n",
    "        listings_fit[\"bath_number\"] = np.round(listings_fit[\"bath_number\"], 0).astype(int)\n",
    "        listings_fit[\"bath_number\"] = np.where(listings_fit[\"bath_number\"] > 3, 4, listings_fit[\"bath_number\"]).astype(str)\n",
    "        listings_fit[\"bedrooms\"] = np.round(listings_fit[\"bedrooms\"], 0).astype(int)\n",
    "        listings_fit[\"bedrooms\"] = np.where(listings_fit[\"bedrooms\"] > 3, 4, listings_fit[\"bedrooms\"]).astype(str)\n",
    "        self.one_hot_columns = [\"bath_number\", \"bedrooms\", \"host_location_country\", \"neighbourhood_cleansed\", \"property_type\", \"room_type\", \"bath_kind\"]        \n",
    "        self.one_hot = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "        self.one_hot.fit(listings_fit[self.one_hot_columns])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform_first(self, fit = True, munich = False):   \n",
    "        # CLEAN HOST LOCATION\n",
    "        country_abr = pd.read_csv(\"https://gist.githubusercontent.com/radcliff/f09c0f88344a7fcef373/raw/2753c482ad091c54b1822288ad2e4811c021d8ec/wikipedia-iso-country-codes.csv\")\n",
    "        country_list = list(country_abr.iloc[:,0])\n",
    "        abr_list = list(country_abr.iloc[:,1])\n",
    "        self.data[\"host_location_country\"] = self.data[\"host_location\"].copy()\n",
    "        for i in list(country_list):\n",
    "            fil = self.data[\"host_location\"].str.contains(i, case = False, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = str(i)\n",
    "        for i,j in enumerate(list(abr_list)):\n",
    "            fil = self.data[\"host_location\"].str.contains(str(j), case = True, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = str(country_list[i])\n",
    "        self.data = self.data.reset_index(drop = True)\n",
    "        for i, j in enumerate(self.country_list):\n",
    "            fil = self.data[\"host_location_country\"].str.contains(j, case = True, na = False)\n",
    "            self.data.loc[fil,\"host_location_country\"] = \"Others\"\n",
    "        self.data.loc[self.data[\"host_location_country\"] == \"53.357852, -6.259787\", \"host_location_country\"] = \"Ireland\"\n",
    "        \n",
    "        # IMPUTATION \n",
    "        # name and description, take room_type instead\n",
    "        ind = self.data[self.data[\"name\"].isna()][\"name\"].index\n",
    "        self.data.loc[ind, \"name\"] = self.data.loc[ind, \"room_type\"]\n",
    "\n",
    "        ind = self.data[self.data[\"description\"].isna()][\"description\"].index\n",
    "        self.data.loc[ind, \"description\"] = self.data.loc[ind, \"room_type\"]\n",
    "        \n",
    "        # neighbourhood-overview (=description) just neihgbourhood cleansed\n",
    "        ind = self.data[self.data[\"neighborhood_overview\"].isna()][\"neighborhood_overview\"].index\n",
    "        self.data.loc[ind, \"neighborhood_overview\"] = self.data.loc[ind, \"neighbourhood_cleansed\"]\n",
    "        # host_about\n",
    "        ind = self.data[self.data[\"host_about\"].isna()][\"host_about\"].index\n",
    "        self.data.loc[ind, \"host_about\"] = \" \"\n",
    "\n",
    "        # first and last review, you might want to think about this again\n",
    "        ind = self.data[self.data[\"first_review\"].isna()][\"first_review\"].index\n",
    "        self.data.loc[ind, \"first_review\"] = self.data.loc[ind, \"last_scraped\"]\n",
    "\n",
    "        ind = self.data[self.data[\"last_review\"].isna()][\"last_review\"].index\n",
    "        self.data.loc[ind, \"last_review\"] = self.data.loc[ind, \"last_scraped\"]\n",
    "\n",
    "        # Reviews per Month are probably zero\n",
    "        ind = self.data[self.data[\"reviews_per_month\"].isna()][\"reviews_per_month\"].index\n",
    "        self.data.loc[ind, \"reviews_per_month\"] = self.data.loc[ind, \"number_of_reviews\"]\n",
    "\n",
    "        if munich:\n",
    "            # If the host_location is not given, they are probably in Germany\n",
    "            ind = self.data[self.data[\"host_location_country\"].isna()][\"host_location_country\"].index\n",
    "            self.data.loc[ind, \"host_location_country\"] = \"Germany\"\n",
    "            \n",
    "        else:\n",
    "            # If the host_location is not given, they are probably in Ireland\n",
    "            ind = self.data[self.data[\"host_location_country\"].isna()][\"host_location_country\"].index\n",
    "            self.data.loc[ind, \"host_location_country\"] = \"Ireland\"\n",
    "\n",
    "        ## Some webscraping for host-variables -> shall be the same profiles\n",
    "        ind_s = self.data[self.data[\"host_name\"].isna()][\"host_name\"].index\n",
    "        rel_URL = self.data.loc[ind_s, \"host_url\"]\n",
    "        ids = self.data.loc[ind_s, \"host_id\"]\n",
    "\n",
    "        name = []\n",
    "        id_ver = []\n",
    "        for i in range(len(ind_s)):\n",
    "            self.data.loc[ind_s, \"host_listings_count\"] = len(self.data[self.data.host_id == ids.values[i]])\n",
    "            session = requests.Session()\n",
    "            html_code = session.get(rel_URL.values[i]).content\n",
    "            soup = bs(html_code, \"html.parser\")\n",
    "            name_html = soup.select(\"._a0kct9 ._14i3z6h\")\n",
    "            # the if statement is for profiles that cannot be called for any reason\n",
    "            if len(name_html) == 0:\n",
    "                name.append(\"Anonymous\")\n",
    "            else:\n",
    "                name.append(name_html[0].text[8:])\n",
    "\n",
    "        self.data.loc[ind_s, \"host_name\"] = name\n",
    "        self.data.loc[ind_s, \"host_since\"] = self.data.loc[ind_s, \"first_review\"]\n",
    "    \n",
    "        # OLS BEDS\n",
    "        ind = self.data[self.data[\"beds\"].isna()][\"beds\"].index\n",
    "        x0 = self.data[\"accommodates\"][ind]\n",
    "        x0 = sm.add_constant(x0)\n",
    "        predictions = self.model_OLS_beds.predict(x0)\n",
    "        prediction = np.where(predictions <= 0.5, 1, predictions)   \n",
    "        self.data.loc[ind, \"beds\"] = round(predictions) \n",
    "        \n",
    "        # OLS BEDROOMS\n",
    "        ind = self.data[self.data[\"bedrooms\"].isna()][\"bedrooms\"].index\n",
    "        x0 = self.data[\"beds\"][ind]\n",
    "        x0 = sm.add_constant(x0)\n",
    "        predictions = self.model_OLS_bedrooms.predict(x0)\n",
    "        prediction = np.where(predictions <= 0.5, 1, predictions)   \n",
    "        self.data.loc[ind, \"bedrooms\"] = round(predictions)\n",
    "        \n",
    "        # REVIEWS HALFNORMAL\n",
    "        for i in range(len(self.review_var)):\n",
    "            ind = self.data[self.data[self.review_var[i]].isna()][self.review_var[i]].index\n",
    "            np.random.seed(123)\n",
    "            fill_ind = (halfnorm.rvs(loc=0, scale=self.sd_reviews[i], size=len(ind)) * -1) + 5\n",
    "            self.data.loc[ind, self.review_var[i]] = fill_ind\n",
    "            \n",
    "        # BINARY IMPUTATION \n",
    "        for i in range(len(self.rest_var)):\n",
    "            ind = self.data[self.data[self.rest_var[i]].isna()][self.rest_var[i]].index\n",
    "            self.data.loc[ind, self.rest_var[i]] = np.random.binomial(n=1, p=self.pis[i], size=len(ind))\n",
    "        \n",
    "        # IMPUTATION TEXT STUFF\n",
    "        for j,i in enumerate(self.text_var):\n",
    "            self.data[i].fillna(self.means_text[j], inplace=True)\n",
    "                       \n",
    "        # IMPUTATION IMAGE STUFF\n",
    "        img_df = pd.read_csv(\"data/img_info.csv\")       \n",
    "        self.room_cols = [\"no_img_bathroom\",\"no_img_bedroom\",\"no_img_dining\",\"no_img_hallway\",\"no_img_kitchen\",\"no_img_living\",\"no_img_others\"] #\"no_img_balcony\",\n",
    "        self.data[\"count\"] = self.data[\"count\"].fillna(0)\n",
    "        self.data[\"brightness\"] = self.data[\"brightness\"].fillna(self.mean_brightness)\n",
    "        self.data[\"contrast\"] = self.data[\"contrast\"].fillna(self.mean_contrast)\n",
    "        if munich:\n",
    "            for i in self.room_cols:\n",
    "                self.data[i] = img_df[i].mean()\n",
    "        else:\n",
    "            self.data[self.room_cols] = self.data[self.room_cols].fillna(0)\n",
    "        \n",
    "        # ONE HOT\n",
    "        self.data[\"bath_number\"] = np.round(self.data[\"bath_number\"], 0).astype(int)\n",
    "        self.data[\"bath_number\"] = np.where(self.data[\"bath_number\"] > 3, 4, self.data[\"bath_number\"]).astype(str)\n",
    "        self.data[\"bedrooms\"] = np.round(self.data[\"bedrooms\"], 0).astype(int)\n",
    "        self.data[\"bedrooms\"] = np.where(self.data[\"bedrooms\"] > 3, 4, self.data[\"bedrooms\"]).astype(str)\n",
    "        one_hots = self.one_hot.transform(self.data[self.one_hot_columns]).toarray().astype(int)\n",
    "        one_hots = pd.DataFrame(one_hots)\n",
    "        one_hots.columns = self.one_hot.get_feature_names_out(input_features = self.one_hot_columns)\n",
    "        self.data = pd.concat([self.data, one_hots], axis=1)\n",
    "        self.data.drop(self.one_hot_columns, axis = 1, inplace = True)\n",
    "\n",
    "        # TIME VARIABLES\n",
    "        date_col = [\"last_scraped\", \"host_since\", \"first_review\", \"last_review\"]\n",
    "        pd.to_datetime(self.data[\"last_scraped\"], yearfirst=True)\n",
    "        date_df = self.data.filter(date_col).apply(pd.to_datetime)\n",
    "        self.data[\"host_since\"] = date_df[\"last_scraped\"] - date_df[\"host_since\"]\n",
    "        self.data[\"first_review\"] = date_df[\"last_scraped\"] - date_df[\"first_review\"]\n",
    "        self.data[\"last_review\"] = date_df[\"last_scraped\"] - date_df[\"last_review\"]\n",
    "        self.data = self.data.drop(\"last_scraped\", axis=1)\n",
    "        # We have a timedelta object in each cell now. We should convert it into an integer using its attribute .days\n",
    "        date_col = date_col[1:]\n",
    "        for i in date_col:\n",
    "            self.data[i] = pd.Series([j.days for j in list(self.data[i])])\n",
    "        \n",
    "        # VARIANCE THRESHOLD\n",
    "       \n",
    "        \n",
    "        if fit:\n",
    "            bin_col = [col for col in self.data if np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "            num_col = [col for col in self.data if ~np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "            binary_df = self.data.filter(bin_col)\n",
    "            sel = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "            sel.feature_names_in_ = binary_df.columns\n",
    "            self.variance_threshold = sel.fit(binary_df)\n",
    "            binary_col = self.variance_threshold.get_feature_names_out()\n",
    "            all_col = binary_col.tolist() + num_col\n",
    "            all_col = np.unique(np.array(all_col)).tolist()        \n",
    "            self.all_col_var = all_col\n",
    "        print(str(len(self.data.columns) - len(self.all_col_var)) + \" binary variables have been removed due to close zero-variance.\")\n",
    "        \n",
    "        self.data = self.data.filter(self.all_col_var)  \n",
    "\n",
    "        # DROP\n",
    "        self.data = self.data.drop([\"host_location\",\"host_id\", \"host_url\", \"name\", \"description\", \"neighborhood_overview\", \"host_name\", \"host_about\"], axis = 1)\n",
    "\n",
    "        # CHECK FOR NaNs\n",
    "        if len(self.data.isna().sum()[self.data.isna().sum().values > 0]) == 0:\n",
    "            print(\"Imputation done. No NaN's are left in the data.\")\n",
    "        else:\n",
    "            print(\"Imputation failed. There are NaN's left; here is where:\")\n",
    "            print(self.data.isna().sum()[self.data.isna().sum().values > 0])\n",
    "\n",
    "        return self.data\n",
    "    \n",
    "    def fit_second(self):\n",
    "        # PCAs FIT\n",
    "        self.city_life = [\"nightclubs\", \"sex_amenities\", \"bicycle_rentals\", \"casinos\", \"university\",     \n",
    "                          \"theatres_artscentre\", \"library\", \"taxi\", \"fast_foods\", \"restaurants\", \"bars\",\n",
    "                          \"cafes\", \"malls\", \"cinemas\", \"supermarkets\", \"bus_train_tram_station\", \"social_amenities\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_city_life = scaler.fit(self.data[self.city_life])\n",
    "        city_life_df = self.scaler_pca_city_life.transform(self.data[self.city_life])\n",
    "        self.pca_city = PCA(n_components = 5).fit(city_life_df)\n",
    "        \n",
    "        # PCA for touristic and travel\n",
    "        self.travel_touristic = [\"neighbourhood_cleansed_Dublin City\", \"in_city\", \"nearest_sight\", \"mean_dist_sight\", \n",
    "                                 \"2nd_nearest_sight\", \"3rd_nearest_sight\", \"nearest_travel_poss\", \"mean_dist_travel\"]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_travel = scaler.fit(self.data[self.travel_touristic])\n",
    "        travel_touristic_df = self.scaler_pca_travel.transform(self.data[self.travel_touristic])\n",
    "        self.pca_travel = PCA(n_components = 1).fit(travel_touristic_df)\n",
    "\n",
    "        # PCA for kitchen + equipment\n",
    "        self.kitchen = [\"Microwave\", \"Dishes and silverware\", \"Refridgerator_available\", \"Dishwasher\",\n",
    "                        \"Stoves_available\", \"Cooking basics\", \"Oven_available\", \"Kitchen_available\"]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_kitchen = scaler.fit(self.data[self.kitchen])\n",
    "        kitchen_df = self.scaler_pca_kitchen.transform(self.data[self.kitchen])\n",
    "        self.pca_kitchen = PCA(n_components = 4).fit(kitchen_df)\n",
    "\n",
    "        # PCA for accommodation size\n",
    "        self.acco = [\"bedrooms_1\", \"bedrooms_2\", \"accommodates\", \"beds\", \"room_type_Entire home/apt\", \"room_type_Private room\",\n",
    "                     \"bath_number_1\", \"bath_number_2\", \"bath_kind_Shared\", \"bath_kind_Private\", \"bath_kind_Normal\",\n",
    "                     \"property_type_Entire residential home\", \"property_type_Entire rental unit\", \"property_type_Others\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_acco = scaler.fit(self.data[self.acco])\n",
    "        accommodation_size_df = self.scaler_pca_acco.transform(self.data[self.acco])\n",
    "        self.pca_acco_size = PCA(n_components = 6).fit(accommodation_size_df)\n",
    "        \n",
    "        # PCA for host listings counts\n",
    "        self.host_listings = [\"calculated_host_listings_count\", \"host_listings_count\", \n",
    "                              \"calculated_host_listings_count_private_rooms\", \"calculated_host_listings_count_shared_rooms\",  \n",
    "                              \"calculated_host_listings_count_entire_homes\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_host = scaler.fit(self.data[self.host_listings])\n",
    "        host_listings_df = self.scaler_pca_host.transform(self.data[self.host_listings])\n",
    "        self.pca_host = PCA(n_components = 3).fit(host_listings_df)\n",
    "       \n",
    "        # PCA for minimum nights\n",
    "        self.min_nights = [\"minimum_nights\", \"minimum_minimum_nights\", \"maximum_minimum_nights\", \"minimum_nights_avg_ntm\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_min_nights = scaler.fit(self.data[self.min_nights])\n",
    "        min_nights_df = self.scaler_pca_min_nights.transform(self.data[self.min_nights])\n",
    "        self.pca_min_nights = PCA(n_components = 1).fit(min_nights_df)\n",
    "\n",
    "        # PCA for availability\n",
    "        self.avail = [\"availability_365\", \"availability_30\", \"availability_60\", \"availability_90\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_avail = scaler.fit(self.data[self.avail])\n",
    "        avail_df = self.scaler_pca_avail.transform(self.data[self.avail])\n",
    "        self.pca_avail = PCA(n_components = 1).fit(avail_df)\n",
    "\n",
    "        # PCA for review total score\n",
    "        self.review_total_scores = [\"review_scores_rating\", \"mean_compound\", \"most_pos_compound\", \"mean_positivity\",\n",
    "                                    \"mean_neutrality\", \"mean_negativity\", \"most_neg_compound\", \"prop_of_neg_comp\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_review = scaler.fit(self.data[self.review_total_scores])\n",
    "        review_total_scores_df = self.scaler_pca_review.transform(self.data[self.review_total_scores])\n",
    "        self.pca_review = PCA(n_components = 4).fit(review_total_scores_df)\n",
    "\n",
    "        # PCA for maximum nights\n",
    "        self.max_nights = [\"maximum_nights\", \"minimum_maximum_nights\", \"maximum_maximum_nights\", \n",
    "                           \"maximum_nights_avg_ntm\", \"Long term stays allowed\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_max_nights = scaler.fit(self.data[self.max_nights])\n",
    "        max_nights_df = self.scaler_pca_max_nights.transform(self.data[self.max_nights])\n",
    "        self.pca_max_nights = PCA(n_components = 1).fit(max_nights_df)\n",
    "\n",
    "        # PCA for amount of reviews\n",
    "        self.review_amount = [\"number_of_reviews_l30d\", \"number_of_reviews_ltm\", \"reviews_per_month\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_review_amount = scaler.fit(self.data[self.review_amount])\n",
    "        review_amount_df = self.scaler_pca_review_amount.transform(self.data[self.review_amount])\n",
    "        self.pca_review_amount = PCA(n_components = 2).fit(review_amount_df)\n",
    "\n",
    "        # PCA for host about\n",
    "        self.host_ab = [\"compound_host_ab\", \"positivity_host_ab\", \"host_about_length\", \"neutrality_host_ab\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_host_ab = scaler.fit(self.data[self.host_ab])\n",
    "        host_ab_df = self.scaler_pca_host_ab.transform(self.data[self.host_ab])\n",
    "        self.pca_host_ab = PCA(n_components = 2).fit(host_ab_df)\n",
    "\n",
    "        # PCA for neighborhood overview\n",
    "        self.neigh_over = [\"compound_neigh_over\", \"positivity_neigh_over\", \"neighborhood_overview_length\", \"neutrality_neigh_over\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_neigh_over = scaler.fit(self.data[self.neigh_over])\n",
    "        neigh_over_df = self.scaler_pca_neigh_over.transform(self.data[self.neigh_over])\n",
    "        self.pca_neigh_over = PCA(n_components = 2).fit(neigh_over_df)\n",
    "\n",
    "        # PCA for amount of reviews\n",
    "        self.descr = [\"compound_descr\", \"positivity_descr\", \"description_length\", \"neutrality_descr\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_descr = scaler.fit(self.data[self.descr])\n",
    "        descr_df = self.scaler_pca_descr.transform(self.data[self.descr])\n",
    "        self.pca_descr = PCA(n_components = 2).fit(descr_df)\n",
    "\n",
    "        # PCAs for image numbers\n",
    "        self.img_no = [\"no_img_others\", \"no_img_hallway\", \"no_img_dining\", \"no_img_bathroom\", \"count\", \n",
    "                       \"no_img_bedroom\", \"no_img_kitchen\", \"no_img_living\"]\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_pca_img_no = scaler.fit(self.data[self.img_no])\n",
    "        img_no_df = self.scaler_pca_img_no.transform(self.data[self.img_no])\n",
    "        self.pca_img_no = PCA(n_components = 5).fit(img_no_df)\n",
    "\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform_second(self):\n",
    "        # PCA TRANSFORMS\n",
    "        city_life_df = self.scaler_pca_city_life.transform(self.data[self.city_life])\n",
    "        city_pcas = self.pca_city.transform(city_life_df)\n",
    "        self.data[\"city_life_pca1\"] = city_pcas[:,0]\n",
    "        self.data[\"city_life_pca2\"] = city_pcas[:,1]\n",
    "        self.data[\"city_life_pca3\"] = city_pcas[:,2]\n",
    "        self.data[\"city_life_pca4\"] = city_pcas[:,3]\n",
    "        self.data[\"city_life_pca5\"] = city_pcas[:,4]\n",
    "        self.data = drop_col(self.data, self.city_life, regex = False)\n",
    "        \n",
    "        travel_touristic_df = self.scaler_pca_travel.transform(self.data[self.travel_touristic])\n",
    "        self.data[\"travel_touristic_pca\"] = self.pca_travel.transform(travel_touristic_df)\n",
    "        self.data = drop_col(self.data, self.travel_touristic, regex = False)\n",
    "\n",
    "        kitchen_df = self.scaler_pca_kitchen.transform(self.data[self.kitchen])\n",
    "        kitchen_pcas = self.pca_kitchen.transform(kitchen_df)\n",
    "        self.data[\"kitchen_pca1\"] = kitchen_pcas[:,0]\n",
    "        self.data[\"kitchen_pca2\"] = kitchen_pcas[:,1]\n",
    "        self.data[\"kitchen_pca3\"] = kitchen_pcas[:,2]\n",
    "        self.data[\"kitchen_pca4\"] = kitchen_pcas[:,3]\n",
    "        self.data = drop_col(self.data, self.kitchen, regex = False)\n",
    "\n",
    "        accommodation_size_df = self.scaler_pca_acco.transform(self.data[self.acco])\n",
    "        acco_size_pcas = self.pca_acco_size.transform(accommodation_size_df)\n",
    "        self.data[\"accommodation_size_pca1\"] = acco_size_pcas[:, 0]\n",
    "        self.data[\"accommodation_size_pca2\"] = acco_size_pcas[:, 1]\n",
    "        self.data[\"accommodation_size_pca3\"] = acco_size_pcas[:, 2]\n",
    "        self.data[\"accommodation_size_pca4\"] = acco_size_pcas[:, 3]\n",
    "        self.data[\"accommodation_size_pca5\"] = acco_size_pcas[:, 4]\n",
    "        self.data[\"accommodation_size_pca6\"] = acco_size_pcas[:, 5]\n",
    "        self.data = drop_col(self.data, self.acco, regex = False)\n",
    "\n",
    "        host_listings_df = self.scaler_pca_host.transform(self.data[self.host_listings])\n",
    "        host_listings_pcas = self.pca_host.transform(host_listings_df)\n",
    "        self.data[\"host_listings_pca1\"] = host_listings_pcas[:,0]\n",
    "        self.data[\"host_listings_pca2\"] = host_listings_pcas[:,1]\n",
    "        self.data[\"host_listings_pca3\"] = host_listings_pcas[:,2]\n",
    "        self.data = drop_col(self.data, self.host_listings, regex = False)\n",
    "        \n",
    "        min_nights_df = self.scaler_pca_min_nights.transform(self.data[self.min_nights])\n",
    "        self.data[\"min_nights_pca\"] = self.pca_min_nights.transform(min_nights_df)\n",
    "        self.data = drop_col(self.data, self.min_nights, regex = False)\n",
    "        \n",
    "        avail_df = self.scaler_pca_avail.transform(self.data[self.avail])\n",
    "        self.data[\"availability_pca\"] = self.pca_avail.transform(avail_df)\n",
    "        self.data = drop_col(self.data, self.avail, regex = False)\n",
    "        \n",
    "        review_total_scores_df = self.scaler_pca_review.transform(self.data[self.review_total_scores])\n",
    "        review_total_pcas = self.pca_review.transform(review_total_scores_df)\n",
    "        self.data[\"review_total_pca1\"] = review_total_pcas[:, 0]\n",
    "        self.data[\"review_total_pca2\"] = review_total_pcas[:, 1]\n",
    "        self.data[\"review_total_pca3\"] = review_total_pcas[:, 2]\n",
    "        self.data[\"review_total_pca4\"] = review_total_pcas[:, 3]\n",
    "        self.data = drop_col(self.data, self.review_total_scores, regex = False)\n",
    "        \n",
    "        max_nights_df = self.scaler_pca_max_nights.transform(self.data[self.max_nights])\n",
    "        self.data[\"max_nights_pca\"] = self.pca_max_nights.transform(max_nights_df)\n",
    "        self.data = drop_col(self.data, self.max_nights, regex = False)\n",
    "        \n",
    "        review_amount_df = self.scaler_pca_review_amount.transform(self.data[self.review_amount])\n",
    "        review_amount_pcas = self.pca_review_amount.transform(review_amount_df)\n",
    "        self.data[\"review_amount_pca1\"] = review_amount_pcas[:,0]\n",
    "        self.data[\"review_amount_pca2\"] = review_amount_pcas[:,1]\n",
    "        self.data = drop_col(self.data, self.review_amount, regex = False)\n",
    "\n",
    "        host_ab_df = self.scaler_pca_host_ab.transform(self.data[self.host_ab])\n",
    "        host_ab_pcas = self.pca_host_ab.transform(host_ab_df)\n",
    "        self.data[\"host_ab_pca1\"] = host_ab_pcas[:,0]\n",
    "        self.data[\"host_ab_pca2\"] = host_ab_pcas[:,1]\n",
    "        self.data = drop_col(self.data, self.host_ab, regex = False)\n",
    "\n",
    "        neigh_over_df = self.scaler_pca_neigh_over.transform(self.data[self.neigh_over])\n",
    "        neigh_over_pcas = self.pca_neigh_over.transform(neigh_over_df)\n",
    "        self.data[\"neigh_over_pca1\"] = neigh_over_pcas[:,0]\n",
    "        self.data[\"neigh_over_pca2\"] = neigh_over_pcas[:,1]\n",
    "        self.data = drop_col(self.data, self.neigh_over, regex = False)\n",
    "\n",
    "        descr_df = self.scaler_pca_descr.transform(self.data[self.descr])\n",
    "        descr_pcas = self.pca_descr.transform(descr_df)\n",
    "        self.data[\"descr_pca1\"] = descr_pcas[:,0]\n",
    "        self.data[\"descr_pca2\"] = descr_pcas[:,1]\n",
    "        self.data = drop_col(self.data, self.descr, regex = False)\n",
    "\n",
    "        # PCA TRANSFORMS\n",
    "        img_no_df = self.scaler_pca_img_no.transform(self.data[self.img_no])\n",
    "        image_pcas = self.pca_img_no.transform(img_no_df)\n",
    "        self.data[\"img_no_pca1\"] = image_pcas[:,0]\n",
    "        self.data[\"img_no_pca2\"] = image_pcas[:,1]\n",
    "        self.data[\"img_no_pca3\"] = image_pcas[:,2]\n",
    "        self.data[\"img_no_pca4\"] = image_pcas[:,3]\n",
    "        self.data[\"img_no_pca5\"] = image_pcas[:,4]\n",
    "        self.data = drop_col(self.data, self.img_no, regex = False)\n",
    "                \n",
    "        # DROP DUE TO CORRELATION  \n",
    "        # keep Dryer available\n",
    "        self.data = drop_col(self.data, [\"Washer_available\"], regex = False) \n",
    "        # no good PCA, keep Shampoo_Conditioner_available\n",
    "        self.data = drop_col(self.data, [\"Hangers\", \"Hair dryer\", \"Iron\"], regex = False) \n",
    "        # keep Washer available, Kitchen in PCA\n",
    "        self.data = drop_col(self.data, [\"Smoke alarm\", \"host_location_country_Ireland\"], regex = False) \n",
    "        # keep fire extinguisher\n",
    "        self.data = drop_col(self.data, [\"First aid kit\"], regex = False) \n",
    "        # keep Bed linens\n",
    "        self.data = drop_col(self.data, [\"Hot water\"], regex = False) \n",
    "        # keep Private Entrance\n",
    "        self.data = drop_col(self.data, [\"Cable TV\", \"Indoor fireplace\"], regex = False) \n",
    "        # keep Safe_available\n",
    "        self.data = drop_col(self.data, [\"Paid_parking\", \"Shower gel\", \"Bathtub\", \"Baby_friendly\",], regex = False) \n",
    "        # Dishwasher in KitchenPCA, keep garden_available\n",
    "        self.data = drop_col(self.data, [\"Coffee_machine_available\", \"Patio_balcony_available\"], regex = False) \n",
    "        # keep Breakfast, bath private in bath PCA\n",
    "        self.data = drop_col(self.data, [\"Host greets you\"], regex = False) \n",
    "        # keep last_review\n",
    "        self.data = drop_col(self.data, [\"first_review\"], regex = False) \n",
    "        # PCA does not work that good, keep \"review_scores_communication\"\n",
    "        self.data = drop_col(self.data, [\"review_scores_location\", \"review_scores_accuracy\",   \n",
    "                                        \"review_scores_cleanliness\", \"review_scores_value\"], regex = False) \n",
    "        # keep breakfast\n",
    "        self.data = drop_col(self.data, [\"Lock on bedroom door\"], regex = False) \n",
    "        # keep Private Entrance\n",
    "        self.data = drop_col(self.data, [\"Safe_available\", \"Garden_backyard_available\"], regex = False) \n",
    "        # will correlate with kitchen pca\n",
    "        self.data = drop_col(self.data, [\"Bed linens\"], regex = False) \n",
    "        \n",
    "        print(\"PCA's built and correlated features dropped.\")\n",
    "        \n",
    "        return self.data\n",
    "    \n",
    "    def fit_third(self):\n",
    "        \n",
    "        # T-TESTS\n",
    "        # get binary variables\n",
    "        bin_col = [col for col in self.data if (np.isin(self.data[col].unique(), [0, 1]).all() or np.isin(self.data[col].unique(), [0., 1.]).all())]\n",
    "\n",
    "        stats_val = []\n",
    "        p_val = []\n",
    "        names = []\n",
    "\n",
    "        price = self.data[\"price\"]\n",
    "        price = price.str.replace(\"$\",\"\")\n",
    "        price = price.str.replace(\",\",\"\")\n",
    "        price = price.astype(float)\n",
    "        price = np.log(price)\n",
    "\n",
    "        p = price\n",
    "        for i in bin_col:\n",
    "            t_Test(self.data[i], p, stats_val, p_val, names)\n",
    "        \n",
    "        p_val_sig = []\n",
    "        for x in p_val:\n",
    "            p_val_sig.append(x < 0.05)\n",
    "        \n",
    "        insig = [x for x, y in zip(names, p_val_sig) if y == False]\n",
    "        self.insig = insig\n",
    "        \n",
    "        num_col = [col for col in self.data if ~np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "        num_col.remove(\"price\")\n",
    "        num_col.remove(\"id\")\n",
    "        scaler = StandardScaler()\n",
    "        self.scaler_final = scaler.fit(self.data[num_col])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform_third(self, log_transform = True, drop_id = True, standardize = True):\n",
    "        # T-TESTS\n",
    "        if len(self.insig) > 0:\n",
    "            self.data = self.data.drop(self.insig, axis = 1)\n",
    "        print(\"Due to insignificant t-tests we drop:\")\n",
    "        print(self.insig)\n",
    "        \n",
    "        price = self.data[\"price\"]\n",
    "        price = price.str.replace(\"$\",\"\")\n",
    "        price = price.str.replace(\",\",\"\")\n",
    "        price = price.astype(float)\n",
    "        \n",
    "        if log_transform:\n",
    "            price = np.log(price)\n",
    "        if drop_id:\n",
    "            self.data.drop(\"id\", axis = 1, inplace = True)\n",
    "            \n",
    "        self.data.drop(\"price\", axis = 1, inplace = True)\n",
    "\n",
    "        num_col = [col for col in self.data if ~np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "        bi_col = [col for col in self.data if np.isin(self.data[col].unique(), [0, 1]).all()]\n",
    "\n",
    "        print(bi_col)\n",
    "        if drop_id == False:\n",
    "            num_col.remove(\"id\")\n",
    "            \n",
    "        if standardize == True:\n",
    "            self.data[num_col] = self.scaler_final.transform(self.data[num_col])\n",
    "        \n",
    "        return self.data, price\n",
    "\n",
    "    def fit_transform(self, X, log_transform = True, drop_id = True):\n",
    "        print('-'*30)\n",
    "        print('Fit and Transform data...')\n",
    "        print('-'*30)\n",
    "        self.data = X\n",
    "        self.data = self.preprocess()\n",
    "        self.data = self.process_amenities(fit = True)\n",
    "        self.data = self.add_stuff()\n",
    "        self.fit_first()\n",
    "        self.data = self.transform_first(fit = True)\n",
    "        self.fit_second()\n",
    "        self.data = self.transform_second()\n",
    "        self.fit_third()\n",
    "        self.data, price = self.transform_third(log_transform, drop_id)\n",
    "        self.data.columns = self.data.columns.str.replace(\" \",\"_\")       \n",
    "        return self.data, price\n",
    "        \n",
    "    def transform(self, X, log_transform = True, drop_id = True):\n",
    "        print('-'*30)\n",
    "        print('Transform data...')\n",
    "        print('-'*30)\n",
    "        self.data = X\n",
    "        self.data = self.preprocess()\n",
    "        self.data = self.process_amenities(fit = False)\n",
    "        self.data = self.add_stuff(munich = True)\n",
    "        self.data = self.transform_first(fit = False, munich = True)\n",
    "        self.data = self.transform_second()\n",
    "        self.data, price = self.transform_third(log_transform, drop_id)       \n",
    "        self.data.columns = self.data.columns.str.replace(\" \",\"_\")       \n",
    "        return self.data, price\n",
    "\n",
    "    def fit_transform_dendro(self, X, log_transform = True, drop_id = True, standardize = True):\n",
    "        print('-'*30)\n",
    "        print('Fit and Transform data...')\n",
    "        print('-'*30)\n",
    "        self.data = X\n",
    "        self.data = self.preprocess()\n",
    "        self.data = self.process_amenities(fit = True)\n",
    "        self.data = self.add_stuff()\n",
    "        self.fit_first()\n",
    "        self.data = self.transform_first(fit = True)\n",
    "        self.fit_third()\n",
    "        self.data, price = self.transform_third(log_transform, drop_id, standardize = standardize)\n",
    "        self.data.columns = self.data.columns.str.replace(\" \",\"_\")       \n",
    "        return self.data, price\n",
    "        \n",
    "    def transform_dendro(self, X, log_transform = True, drop_id = True, standardize = True):\n",
    "        print('-'*30)\n",
    "        print('Transform data...')\n",
    "        print('-'*30)\n",
    "        self.data = X\n",
    "        self.data = self.preprocess()\n",
    "        self.data = self.process_amenities(fit = False)\n",
    "        self.data = self.add_stuff(munich = True)\n",
    "        self.data = self.transform_first(fit = False, munich = True)\n",
    "        self.data, price = self.transform_third(log_transform, drop_id, standardize = standardize)\n",
    "        self.data.columns = self.data.columns.str.replace(\" \",\"_\")       \n",
    "        return self.data, price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(random_seed = 123, test_split = 0.2, val_split = 0.1, for_dendro = False, drop_id = True, standardize = True):\n",
    "    url_listing = \"http://data.insideairbnb.com/ireland/leinster/dublin/2021-11-07/data/listings.csv.gz\"\n",
    "    listings = pd.read_csv(url_listing)\n",
    "    \n",
    "    # remove extreme prices\n",
    "    price = listings[\"price\"]\n",
    "    price = price.str.replace(\"$\",\"\")\n",
    "    price = price.str.replace(\",\",\"\")\n",
    "    price = price.astype(float)\n",
    "    filter = price < 500\n",
    "    listings = listings[filter]\n",
    "    wrangler = Wrangler()\n",
    "    \n",
    "    X_train, X_test = train_test_split(listings, random_state = random_seed, test_size = test_split)\n",
    "    X_train, X_val = train_test_split(X_train, random_state = random_seed, test_size = val_split)\n",
    "    \n",
    "    if for_dendro:\n",
    "        X_train, y_train = wrangler.fit_transform_dendro(X_train, drop_id=drop_id, standardize=standardize)\n",
    "  \n",
    "    else :\n",
    "        X_train, y_train = wrangler.fit_transform(X_train, drop_id=drop_id)\n",
    " \n",
    "\n",
    "\n",
    "    url_listing = \"http://data.insideairbnb.com/germany/bv/munich/2021-12-24/data/listings.csv.gz\"\n",
    "    listing_munich = pd.read_csv(url_listing)\n",
    "\n",
    "    # remove extreme prices\n",
    "    price = listing_munich[\"price\"]\n",
    "    price = price.str.replace(\"$\",\"\")\n",
    "    price = price.str.replace(\",\",\"\")\n",
    "    price = price.astype(float)\n",
    "    filter = price < 500\n",
    "    listing_munich = listing_munich[filter]\n",
    "    \n",
    "    if for_dendro:\n",
    "        X_munich, y_munich = wrangler.transform_dendro(listing_munich, drop_id=drop_id, standardize=standardize)\n",
    "  \n",
    "    else :\n",
    "         X_munich, y_munich = wrangler.transform(listing_munich, drop_id=drop_id)\n",
    "\n",
    "\n",
    "    return X_train, X_munich, y_train, y_munich\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fit and Transform data...\n",
      "------------------------------\n",
      "58 amenities have been removed due to close zero-variance.\n",
      "Text, OpenStreet and image data loaded.\n",
      "44 binary variables have been removed due to close zero-variance.\n",
      "Imputation done. No NaN's are left in the data.\n",
      "PCA's built and correlated features dropped.\n",
      "Due to insignificant t-tests we drop:\n",
      "['Extra pillows and blankets', 'Free_parking', 'Luggage dropoff allowed', 'host_is_superhost', 'host_name_sounds_rare', 'host_name_sounds_west', 'neighbourhood_cleansed_Dn Laoghaire-Rathdown']\n",
      "['Breakfast', 'Carbon monoxide alarm', 'Dryer_available', 'Elevator', 'Fire extinguisher', 'Private entrance', 'Shampoo_Conditioner_available', 'TV_available', 'Workspace', 'host_identity_verified', 'instant_bookable', 'kiosks']\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2 \n",
    "val_split = 0.1 \n",
    "for_dendro = False \n",
    "drop_id = True \n",
    "standardize = True\n",
    "random_seed = 123\n",
    "url_listing = \"http://data.insideairbnb.com/ireland/leinster/dublin/2021-11-07/data/listings.csv.gz\"\n",
    "listings = pd.read_csv(url_listing)\n",
    "\n",
    "# remove extreme prices\n",
    "price = listings[\"price\"]\n",
    "price = price.str.replace(\"$\",\"\")\n",
    "price = price.str.replace(\",\",\"\")\n",
    "price = price.astype(float)\n",
    "filter = price < 500\n",
    "listings = listings[filter]\n",
    "\n",
    "wrangler = Wrangler()\n",
    "\n",
    "X_train, X_test = train_test_split(listings, random_state = random_seed, test_size = test_split)\n",
    "X_train, X_val = train_test_split(X_train, random_state = random_seed, test_size = val_split)\n",
    "\n",
    "if for_dendro:\n",
    "    X_train, y_train = wrangler.fit_transform_dendro(X_train, drop_id=drop_id, standardize=standardize)\n",
    "\n",
    "else :\n",
    "    X_train, y_train = wrangler.fit_transform(X_train, drop_id=drop_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Transform data...\n",
      "------------------------------\n",
      "58 amenities have been removed due to close zero-variance.\n",
      "Text, OpenStreet and image data loaded.\n",
      "44 binary variables have been removed due to close zero-variance.\n",
      "Imputation done. No NaN's are left in the data.\n",
      "PCA's built and correlated features dropped.\n",
      "Due to insignificant t-tests we drop:\n",
      "['Extra pillows and blankets', 'Free_parking', 'Luggage dropoff allowed', 'host_is_superhost', 'host_name_sounds_rare', 'host_name_sounds_west', 'neighbourhood_cleansed_Dn Laoghaire-Rathdown']\n"
     ]
    }
   ],
   "source": [
    "url_listing = \"http://data.insideairbnb.com/germany/bv/munich/2021-12-24/data/listings.csv.gz\"\n",
    "listing_munich = pd.read_csv(url_listing)\n",
    "\n",
    "# remove extreme prices\n",
    "price = listing_munich[\"price\"]\n",
    "price = price.str.replace(\"$\",\"\")\n",
    "price = price.str.replace(\",\",\"\")\n",
    "price = price.astype(float)\n",
    "filter = price < 500\n",
    "listing_munich = listing_munich[filter]\n",
    "\n",
    "if for_dendro:\n",
    "     X_munich, y_munich = wrangler.transform_dendro(listing_munich, drop_id=drop_id, standardize=standardize)\n",
    "\n",
    "else:\n",
    "    X_munich, y_munich = wrangler.transform(listing_munich, drop_id=drop_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Carbon_monoxide_alarm</th>\n",
       "      <th>Dryer_available</th>\n",
       "      <th>Elevator</th>\n",
       "      <th>Fire_extinguisher</th>\n",
       "      <th>Private_entrance</th>\n",
       "      <th>Shampoo_Conditioner_available</th>\n",
       "      <th>TV_available</th>\n",
       "      <th>Workspace</th>\n",
       "      <th>brightness</th>\n",
       "      <th>...</th>\n",
       "      <th>host_ab_pca2</th>\n",
       "      <th>neigh_over_pca1</th>\n",
       "      <th>neigh_over_pca2</th>\n",
       "      <th>descr_pca1</th>\n",
       "      <th>descr_pca2</th>\n",
       "      <th>img_no_pca1</th>\n",
       "      <th>img_no_pca2</th>\n",
       "      <th>img_no_pca3</th>\n",
       "      <th>img_no_pca4</th>\n",
       "      <th>img_no_pca5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.408048</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.036208</td>\n",
       "      <td>0.452826</td>\n",
       "      <td>0.513150</td>\n",
       "      <td>-0.363025</td>\n",
       "      <td>-1.339819</td>\n",
       "      <td>-0.158357</td>\n",
       "      <td>0.113811</td>\n",
       "      <td>-0.209549</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.066676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.408048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425611</td>\n",
       "      <td>-0.850960</td>\n",
       "      <td>0.225094</td>\n",
       "      <td>-0.965836</td>\n",
       "      <td>-1.192193</td>\n",
       "      <td>-0.158357</td>\n",
       "      <td>0.113811</td>\n",
       "      <td>-0.209549</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.066676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.408048</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.340283</td>\n",
       "      <td>-0.850960</td>\n",
       "      <td>0.225094</td>\n",
       "      <td>-0.036826</td>\n",
       "      <td>-1.238351</td>\n",
       "      <td>-0.158357</td>\n",
       "      <td>0.113811</td>\n",
       "      <td>-0.209549</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.066676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.408048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282520</td>\n",
       "      <td>-0.809159</td>\n",
       "      <td>0.062965</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>-1.155745</td>\n",
       "      <td>-0.158357</td>\n",
       "      <td>0.113811</td>\n",
       "      <td>-0.209549</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.066676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.408048</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.084792</td>\n",
       "      <td>-0.850960</td>\n",
       "      <td>0.225094</td>\n",
       "      <td>0.088669</td>\n",
       "      <td>-1.090521</td>\n",
       "      <td>-0.158357</td>\n",
       "      <td>0.113811</td>\n",
       "      <td>-0.209549</td>\n",
       "      <td>-0.015255</td>\n",
       "      <td>-0.066676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Breakfast  Carbon_monoxide_alarm  Dryer_available  Elevator  \\\n",
       "0          0                      1                0         0   \n",
       "1          0                      1                1         0   \n",
       "2          1                      1                0         1   \n",
       "3          0                      0                0         0   \n",
       "4          1                      0                0         0   \n",
       "\n",
       "   Fire_extinguisher  Private_entrance  Shampoo_Conditioner_available  \\\n",
       "0                  0                 0                              1   \n",
       "1                  0                 0                              1   \n",
       "2                  1                 0                              1   \n",
       "3                  0                 1                              1   \n",
       "4                  1                 0                              1   \n",
       "\n",
       "   TV_available  Workspace  brightness  ...  host_ab_pca2  neigh_over_pca1  \\\n",
       "0             1          1   -2.408048  ...     -1.036208         0.452826   \n",
       "1             1          1   -2.408048  ...     -0.425611        -0.850960   \n",
       "2             1          1   -2.408048  ...     -1.340283        -0.850960   \n",
       "3             1          1   -2.408048  ...      0.282520        -0.809159   \n",
       "4             1          1   -2.408048  ...     -1.084792        -0.850960   \n",
       "\n",
       "   neigh_over_pca2  descr_pca1  descr_pca2  img_no_pca1  img_no_pca2  \\\n",
       "0         0.513150   -0.363025   -1.339819    -0.158357     0.113811   \n",
       "1         0.225094   -0.965836   -1.192193    -0.158357     0.113811   \n",
       "2         0.225094   -0.036826   -1.238351    -0.158357     0.113811   \n",
       "3         0.062965    0.045203   -1.155745    -0.158357     0.113811   \n",
       "4         0.225094    0.088669   -1.090521    -0.158357     0.113811   \n",
       "\n",
       "   img_no_pca3  img_no_pca4  img_no_pca5  \n",
       "0    -0.209549    -0.015255    -0.066676  \n",
       "1    -0.209549    -0.015255    -0.066676  \n",
       "2    -0.209549    -0.015255    -0.066676  \n",
       "3    -0.209549    -0.015255    -0.066676  \n",
       "4    -0.209549    -0.015255    -0.066676  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_munich.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['host_identity_verified', 'instant_bookable', 'Breakfast', 'Carbon_monoxide_alarm', 'Elevator', 'Fire_extinguisher', 'Private_entrance', 'Workspace', 'Shampoo_Conditioner_available', 'Dryer_available', 'TV_available', 'kiosks', 'host_since', 'latitude', 'longitude', 'number_of_reviews', 'last_review', 'review_scores_communication', 'name_length', 'prop_of_eng_reviews', 'mean_review_length', 'negativity_descr', 'negativity_neigh_over', 'negativity_host_ab', 'parking', 'brightness', 'contrast', 'city_life_pca1', 'city_life_pca2', 'city_life_pca3', 'city_life_pca4', 'city_life_pca5', 'travel_touristic_pca', 'kitchen_pca1', 'kitchen_pca2', 'kitchen_pca3', 'kitchen_pca4', 'accommodation_size_pca1', 'accommodation_size_pca2', 'accommodation_size_pca3', 'accommodation_size_pca4', 'accommodation_size_pca5', 'accommodation_size_pca6', 'host_listings_pca1', 'host_listings_pca2', 'host_listings_pca3', 'min_nights_pca', 'availability_pca', 'review_total_pca1', 'review_total_pca2', 'review_total_pca3', 'review_total_pca4', 'max_nights_pca', 'review_amount_pca1', 'review_amount_pca2', 'host_ab_pca1', 'host_ab_pca2', 'neigh_over_pca1', 'neigh_over_pca2', 'descr_pca1', 'descr_pca2', 'img_no_pca1', 'img_no_pca2', 'img_no_pca3', 'img_no_pca4', 'img_no_pca5']\n"
     ]
    }
   ],
   "source": [
    "print(wrangler.data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Fit and Transform data...\n",
      "------------------------------\n",
      "58 amenities have been removed due to close zero-variance.\n",
      "Text, OpenStreet and image data loaded.\n",
      "44 binary variables have been removed due to close zero-variance.\n",
      "Imputation done. No NaN's are left in the data.\n",
      "PCA's built and correlated features dropped.\n",
      "Due to insignificant t-tests we drop:\n",
      "['Extra pillows and blankets', 'Free_parking', 'Luggage dropoff allowed', 'host_is_superhost', 'host_name_sounds_rare', 'host_name_sounds_west', 'neighbourhood_cleansed_Dn Laoghaire-Rathdown']\n",
      "------------------------------\n",
      "Transform data...\n",
      "------------------------------\n",
      "58 amenities have been removed due to close zero-variance.\n",
      "Text, OpenStreet and image data loaded.\n",
      "44 binary variables have been removed due to close zero-variance.\n",
      "Imputation done. No NaN's are left in the data.\n",
      "PCA's built and correlated features dropped.\n",
      "Due to insignificant t-tests we drop:\n",
      "['Extra pillows and blankets', 'Free_parking', 'Luggage dropoff allowed', 'host_is_superhost', 'host_name_sounds_rare', 'host_name_sounds_west', 'neighbourhood_cleansed_Dn Laoghaire-Rathdown']\n"
     ]
    }
   ],
   "source": [
    "X_train, X_munich, y_train, y_munich = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_df = pd.read_csv(\"data/img_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index              3.091000e+03\n",
       "id                 2.572424e+07\n",
       "count              1.405111e+01\n",
       "brightness         1.301974e+02\n",
       "contrast           9.704284e-01\n",
       "no_img_bathroom    1.809316e+00\n",
       "no_img_bedroom     3.589034e+00\n",
       "no_img_dining      5.600841e-01\n",
       "no_img_hallway     5.793304e-01\n",
       "no_img_kitchen     2.076824e+00\n",
       "no_img_living      2.182112e+00\n",
       "no_img_others      3.254407e+00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_listing = \"http://data.insideairbnb.com/germany/bv/munich/2021-12-24/data/listings.csv.gz\"\n",
    "listing_munich = pd.read_csv(url_listing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>scrape_id</th>\n",
       "      <th>last_scraped</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>picture_url</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_url</th>\n",
       "      <th>...</th>\n",
       "      <th>count</th>\n",
       "      <th>brightness</th>\n",
       "      <th>contrast</th>\n",
       "      <th>no_img_bathroom</th>\n",
       "      <th>no_img_bedroom</th>\n",
       "      <th>no_img_dining</th>\n",
       "      <th>no_img_hallway</th>\n",
       "      <th>no_img_kitchen</th>\n",
       "      <th>no_img_living</th>\n",
       "      <th>no_img_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97945</td>\n",
       "      <td>https://www.airbnb.com/rooms/97945</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Deluxw-Apartm. with roof terrace</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;We offer a modern, quiet...</td>\n",
       "      <td>We are living in a outskirt of Munich its call...</td>\n",
       "      <td>https://a0.muscache.com/pictures/2459996/10b4c...</td>\n",
       "      <td>517685</td>\n",
       "      <td>https://www.airbnb.com/users/show/517685</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114695</td>\n",
       "      <td>https://www.airbnb.com/rooms/114695</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Apartment Munich/East with sundeck</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;It´s a quiet and sunny a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/21571874/960e...</td>\n",
       "      <td>581737</td>\n",
       "      <td>https://www.airbnb.com/users/show/581737</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127383</td>\n",
       "      <td>https://www.airbnb.com/rooms/127383</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>City apartment next to Pinakothek</td>\n",
       "      <td>&lt;b&gt;The space&lt;/b&gt;&lt;br /&gt;My cosy apartment is loc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/79238c11-bc61...</td>\n",
       "      <td>630556</td>\n",
       "      <td>https://www.airbnb.com/users/show/630556</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159634</td>\n",
       "      <td>https://www.airbnb.com/rooms/159634</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Fancy, bright central roof top flat and homeof...</td>\n",
       "      <td>In this idyllic stylish flat you live very qui...</td>\n",
       "      <td>Very quiet, green, squirrels and beergardens a...</td>\n",
       "      <td>https://a0.muscache.com/pictures/4203267/08141...</td>\n",
       "      <td>765694</td>\n",
       "      <td>https://www.airbnb.com/users/show/765694</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170154</td>\n",
       "      <td>https://www.airbnb.com/rooms/170154</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Own floor &amp; bath, parking &amp; breakfast</td>\n",
       "      <td>Enjoy a quiet neighbourhood, easy access to th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/31636890/593e...</td>\n",
       "      <td>108297</td>\n",
       "      <td>https://www.airbnb.com/users/show/108297</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>53933449</td>\n",
       "      <td>https://www.airbnb.com/rooms/53933449</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Tiny House  \"Holzofen Lodge\"</td>\n",
       "      <td>Es ist ein Brunnen mit gutem Wasser und ein St...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>8767947</td>\n",
       "      <td>https://www.airbnb.com/users/show/8767947</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>53935376</td>\n",
       "      <td>https://www.airbnb.com/rooms/53935376</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Haus mit Garten im grünen Münchner Westen</td>\n",
       "      <td>Nur 6 Minuten vom Pasinger Marienplatz mit zah...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>22253535</td>\n",
       "      <td>https://www.airbnb.com/users/show/22253535</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>53936793</td>\n",
       "      <td>https://www.airbnb.com/rooms/53936793</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Dein neues Zuhause in München -schönes Zimmer</td>\n",
       "      <td>Wir vermieten top ausgestattete Zimmer mit eig...</td>\n",
       "      <td>Sehr ruhige Wohngegend</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>434644613</td>\n",
       "      <td>https://www.airbnb.com/users/show/434644613</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>53945865</td>\n",
       "      <td>https://www.airbnb.com/rooms/53945865</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Modern 125Sqm 2BR apartment, carpark, Olympia ...</td>\n",
       "      <td>Our apartment has suited our family of four we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/d04c7c23-f8dd...</td>\n",
       "      <td>10419667</td>\n",
       "      <td>https://www.airbnb.com/users/show/10419667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>53949583</td>\n",
       "      <td>https://www.airbnb.com/rooms/53949583</td>\n",
       "      <td>20211224070709</td>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>Amazing Duplex flat with balcony</td>\n",
       "      <td>Wunderschöne Maisonette-Wohnung mit einzigarti...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://a0.muscache.com/pictures/miso/Hosting-...</td>\n",
       "      <td>434352177</td>\n",
       "      <td>https://www.airbnb.com/users/show/434352177</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4995 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                            listing_url       scrape_id  \\\n",
       "0        97945     https://www.airbnb.com/rooms/97945  20211224070709   \n",
       "1       114695    https://www.airbnb.com/rooms/114695  20211224070709   \n",
       "2       127383    https://www.airbnb.com/rooms/127383  20211224070709   \n",
       "3       159634    https://www.airbnb.com/rooms/159634  20211224070709   \n",
       "4       170154    https://www.airbnb.com/rooms/170154  20211224070709   \n",
       "...        ...                                    ...             ...   \n",
       "4990  53933449  https://www.airbnb.com/rooms/53933449  20211224070709   \n",
       "4991  53935376  https://www.airbnb.com/rooms/53935376  20211224070709   \n",
       "4992  53936793  https://www.airbnb.com/rooms/53936793  20211224070709   \n",
       "4993  53945865  https://www.airbnb.com/rooms/53945865  20211224070709   \n",
       "4994  53949583  https://www.airbnb.com/rooms/53949583  20211224070709   \n",
       "\n",
       "     last_scraped                                               name  \\\n",
       "0      2021-12-24                   Deluxw-Apartm. with roof terrace   \n",
       "1      2021-12-24                 Apartment Munich/East with sundeck   \n",
       "2      2021-12-24                  City apartment next to Pinakothek   \n",
       "3      2021-12-24  Fancy, bright central roof top flat and homeof...   \n",
       "4      2021-12-24              Own floor & bath, parking & breakfast   \n",
       "...           ...                                                ...   \n",
       "4990   2021-12-24                       Tiny House  \"Holzofen Lodge\"   \n",
       "4991   2021-12-24          Haus mit Garten im grünen Münchner Westen   \n",
       "4992   2021-12-24      Dein neues Zuhause in München -schönes Zimmer   \n",
       "4993   2021-12-24  Modern 125Sqm 2BR apartment, carpark, Olympia ...   \n",
       "4994   2021-12-24                   Amazing Duplex flat with balcony   \n",
       "\n",
       "                                            description  \\\n",
       "0     <b>The space</b><br />We offer a modern, quiet...   \n",
       "1     <b>The space</b><br />It´s a quiet and sunny a...   \n",
       "2     <b>The space</b><br />My cosy apartment is loc...   \n",
       "3     In this idyllic stylish flat you live very qui...   \n",
       "4     Enjoy a quiet neighbourhood, easy access to th...   \n",
       "...                                                 ...   \n",
       "4990  Es ist ein Brunnen mit gutem Wasser und ein St...   \n",
       "4991  Nur 6 Minuten vom Pasinger Marienplatz mit zah...   \n",
       "4992  Wir vermieten top ausgestattete Zimmer mit eig...   \n",
       "4993  Our apartment has suited our family of four we...   \n",
       "4994  Wunderschöne Maisonette-Wohnung mit einzigarti...   \n",
       "\n",
       "                                  neighborhood_overview  \\\n",
       "0     We are living in a outskirt of Munich its call...   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     Very quiet, green, squirrels and beergardens a...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "4990                                                NaN   \n",
       "4991                                                NaN   \n",
       "4992                             Sehr ruhige Wohngegend   \n",
       "4993                                                NaN   \n",
       "4994                                                NaN   \n",
       "\n",
       "                                            picture_url    host_id  \\\n",
       "0     https://a0.muscache.com/pictures/2459996/10b4c...     517685   \n",
       "1     https://a0.muscache.com/pictures/21571874/960e...     581737   \n",
       "2     https://a0.muscache.com/pictures/79238c11-bc61...     630556   \n",
       "3     https://a0.muscache.com/pictures/4203267/08141...     765694   \n",
       "4     https://a0.muscache.com/pictures/31636890/593e...     108297   \n",
       "...                                                 ...        ...   \n",
       "4990  https://a0.muscache.com/pictures/miso/Hosting-...    8767947   \n",
       "4991  https://a0.muscache.com/pictures/miso/Hosting-...   22253535   \n",
       "4992  https://a0.muscache.com/pictures/miso/Hosting-...  434644613   \n",
       "4993  https://a0.muscache.com/pictures/d04c7c23-f8dd...   10419667   \n",
       "4994  https://a0.muscache.com/pictures/miso/Hosting-...  434352177   \n",
       "\n",
       "                                         host_url  ... count brightness  \\\n",
       "0        https://www.airbnb.com/users/show/517685  ...   NaN        NaN   \n",
       "1        https://www.airbnb.com/users/show/581737  ...   NaN        NaN   \n",
       "2        https://www.airbnb.com/users/show/630556  ...   NaN        NaN   \n",
       "3        https://www.airbnb.com/users/show/765694  ...   NaN        NaN   \n",
       "4        https://www.airbnb.com/users/show/108297  ...   NaN        NaN   \n",
       "...                                           ...  ...   ...        ...   \n",
       "4990    https://www.airbnb.com/users/show/8767947  ...   NaN        NaN   \n",
       "4991   https://www.airbnb.com/users/show/22253535  ...   NaN        NaN   \n",
       "4992  https://www.airbnb.com/users/show/434644613  ...   NaN        NaN   \n",
       "4993   https://www.airbnb.com/users/show/10419667  ...   NaN        NaN   \n",
       "4994  https://www.airbnb.com/users/show/434352177  ...   NaN        NaN   \n",
       "\n",
       "     contrast no_img_bathroom no_img_bedroom no_img_dining no_img_hallway  \\\n",
       "0         NaN             NaN            NaN           NaN            NaN   \n",
       "1         NaN             NaN            NaN           NaN            NaN   \n",
       "2         NaN             NaN            NaN           NaN            NaN   \n",
       "3         NaN             NaN            NaN           NaN            NaN   \n",
       "4         NaN             NaN            NaN           NaN            NaN   \n",
       "...       ...             ...            ...           ...            ...   \n",
       "4990      NaN             NaN            NaN           NaN            NaN   \n",
       "4991      NaN             NaN            NaN           NaN            NaN   \n",
       "4992      NaN             NaN            NaN           NaN            NaN   \n",
       "4993      NaN             NaN            NaN           NaN            NaN   \n",
       "4994      NaN             NaN            NaN           NaN            NaN   \n",
       "\n",
       "     no_img_kitchen no_img_living no_img_others  \n",
       "0               NaN           NaN           NaN  \n",
       "1               NaN           NaN           NaN  \n",
       "2               NaN           NaN           NaN  \n",
       "3               NaN           NaN           NaN  \n",
       "4               NaN           NaN           NaN  \n",
       "...             ...           ...           ...  \n",
       "4990            NaN           NaN           NaN  \n",
       "4991            NaN           NaN           NaN  \n",
       "4992            NaN           NaN           NaN  \n",
       "4993            NaN           NaN           NaN  \n",
       "4994            NaN           NaN           NaN  \n",
       "\n",
       "[4995 rows x 85 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_munich.merge(img_df, on = \"id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0e252e38867c5c5dbaa4d840f6f52d4785511881d0242d037299812a0aec8ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('tensorflow_m1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
